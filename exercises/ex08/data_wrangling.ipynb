{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX08: Data Wrangling\n",
    "\n",
    "You will define and use functions that are commonly useful when _wrangling_ data in this exercise. You will frequently need your data to be organized in specific ways in order to perform analysis on it and that organization is rarely exactly the \"shape\" the data is stored in (such as a CSV table). Data _wrangling_ is the process of loading, converting, and reorganizing data so that you can analyze it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement the utility functions for this exercise in the `data_utils.py` file found in the `exercises/ex08` directory. As you now know, when you import modules in a running Python program, the module is evaluated only once. Since your Jupyter Notebook _kernel_ is running the entire time you are working on functions in `data_utils.py`, we will use a special extension to automatically reload any changes you make _and save_ in modules you import. The special conventions in the cell below are turning this feature on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoreload of imported modules enabled. Be sure to save your work in other modules!\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "print(\"Autoreload of imported modules enabled. Be sure to save your work in other modules!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data files will be stored in the `data` directory of the workspace. This Notebook is located in `exercises/ex08` directory. If you think of how to _navigate_ from this directory to the `data` directory, you would need to go \"two directories up\" and then \"into the `data` directory\". The constant `DATA_DIRECTORY` defined below uses the convention of two dots to refer to \"one directory up\", so it is a `str` that references the `data` directory _relative_ to this exercise's directory.\n",
    "\n",
    "Then, another constant is established referencing the path to the data file you will use to test your functions in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY=\"../../data\"\n",
    "DATA_FILE_PATH=f\"{DATA_DIRECTORY}/nc_durham_2015_march_21_to_26.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0. Reading Data from a Stored CSV File into Memory\n",
    "\n",
    "In this part of the exercise, you will implement utility functions to read a CSV file from your computer's hard-drive storage into your running program's (Jupyter kernel's) memory. Once in memory, computations over the data set are very fast.\n",
    "\n",
    "By default, your CSV file is read in row-by-row. Storing these rows as a list of \"row\" dictionaries is one way of _representing_ tabular data.\n",
    "\n",
    "### 0.0) Implement the `read_csv_rows` Function\n",
    "\n",
    "Complete the implementation of the `read_csv_rows` function in `data_utils.py` and be sure to save your work when making changes in that file _before_ re-evaluating the cell below to test it.\n",
    "\n",
    "Purpose: Read an entire CSV of data into a `list` of rows, each row represented as `dict[str, str]`.\n",
    "\n",
    "* Function Name: `read_csv_rows`\n",
    "* Parameter: \n",
    "    1. `str` path to CSV file\n",
    "* Return Type: `list[dict[str, str]]` \n",
    "\n",
    "Implementation hint: refer back to the code you wrote in lecture on 10/19 for reading a CSV file. We give you the code for this function.\n",
    "\n",
    "There _should be_ 294 rows and 29 columns read from the `nc_durham_2015_march_21_to_26.csv` stops file. Additionally, the column names should print below those stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jlwilliams90\\Documents\\comp110-22f-workspace\\exercises\\ex08\\data_wrangling.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jlwilliams90/Documents/comp110-22f-workspace/exercises/ex08/data_wrangling.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdata_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m column_values\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jlwilliams90/Documents/comp110-22f-workspace/exercises/ex08/data_wrangling.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m subject_age: \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m column_values(data_rows, \u001b[39m\"\u001b[39m\u001b[39msubject_age\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jlwilliams90/Documents/comp110-22f-workspace/exercises/ex08/data_wrangling.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(subject_age) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'data_utils'"
     ]
    }
   ],
   "source": [
    "from data_utils import column_values\n",
    "\n",
    "subject_age: list[str] = column_values(data_rows, \"subject_age\")\n",
    "\n",
    "if len(subject_age) == 0:\n",
    "    print(\"Complete your implementation of column_values in data_utils.py\")\n",
    "    print(\"Be sure to follow the guidelines above and save your work before re-evaluating!\")\n",
    "else:\n",
    "    print(f\"Column 'subject_age' has {len(subject_age)} values.\")\n",
    "    print(\"The first five values are:\")\n",
    "    for i in range(5):\n",
    "        print(subject_age[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2) `columnar` Function\n",
    "\n",
    "Define and implement this function in `data_utils.py`.\n",
    "\n",
    "Purpose: _Transform_ a table represented as a list of rows (e.g. `list[dict[str, str]]`) into one represented as a dictionary of columns (e.g. `dict[str, list[str]]`).\n",
    "\n",
    "Why is this function useful? Many types of analysis are much easier to perform column-wise.\n",
    "\n",
    "* Function Name: `columnar`\n",
    "* Parameter: `list[dict[str, str]]` - a \"table\" organized as a list of rows\n",
    "* Return Type: `dict[str, list[str]]` - a \"table\" organized as a dictionary of columns\n",
    "\n",
    "Implementation strategy: Establish an empty dictionary to the your column-oriented table you are building up to ultimately return. Loop through each of the column names in the first row of the parameter. Get a list of each column's values via your `column_values` function defined previously. Then, associate the column name with the list of its values in the dictionary you established. After looping through every column name, return the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jlwilliams90\\Documents\\comp110-22f-workspace\\exercises\\ex08\\data_wrangling.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jlwilliams90/Documents/comp110-22f-workspace/exercises/ex08/data_wrangling.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdata_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m columnar\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jlwilliams90/Documents/comp110-22f-workspace/exercises/ex08/data_wrangling.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data_cols: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m columnar(data_rows)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jlwilliams90/Documents/comp110-22f-workspace/exercises/ex08/data_wrangling.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data_cols\u001b[39m.\u001b[39mkeys()) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'data_utils'"
     ]
    }
   ],
   "source": [
    "from data_utils import columnar\n",
    "\n",
    "data_cols: dict[str, list[str]] = columnar(data_rows)\n",
    "\n",
    "if len(data_cols.keys()) == 0:\n",
    "    print(\"Complete your implementation of columnar in data_utils.py\")\n",
    "    print(\"Be sure to follow the guidelines above and save your work before re-evaluating!\")\n",
    "else:\n",
    "    print(f\"{len(data_cols.keys())} columns\")\n",
    "    print(f\"{len(data_cols['subject_age'])} rows\")\n",
    "    print(f\"Columns names: {data_cols.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Selecting (\"narrowing down\") a Data Table\n",
    "\n",
    "When working with a data set, it is useful to inspect the contents of the table you are working with in order to both be convinced your analysis is on the correct path and to know what steps to take next with specific column names or values.\n",
    "\n",
    "In this part of the exercise, you will write some useful utility functions to view the first `N` rows of a column-based table (a function named `head`, referring to the top rows of a table) and another function `select` for producing a simpler data table with only the subset of original columns you care about.\n",
    "\n",
    "### Displaying Tabular data with the `tabulate` 3rd Party Library\n",
    "\n",
    "Reading Python's `str` representations of tabular data, in either representation strategy we used above (list of rows vs. dict of cols), is uncomprehensible for data wrangling. This kind of problem is so common a 3rd party library called `tabulate` is commonly used to produce tables in Jupyter Notebooks. This library was was included in your workspace's `requirements.txt` file at the beginning of the semester, so you should already have it installed!\n",
    "\n",
    "For a quick demonstration of how the `tabulate` library works, consider this simple demo below. You should be able to evaluate it as is without any further changes and see the tabular representation appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67c2cea2dfa02739b0de49bc0d5f8f053e7b187cb2e731547eaa2a1aa6ff9c35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
