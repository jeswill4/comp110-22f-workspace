{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX08: Data Wrangling\n",
    "\n",
    "You will define and use functions that are commonly useful when _wrangling_ data in this exercise. You will frequently need your data to be organized in specific ways in order to perform analysis on it and that organization is rarely exactly the \"shape\" the data is stored in (such as a CSV table). Data _wrangling_ is the process of loading, converting, and reorganizing data so that you can analyze it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement the utility functions for this exercise in the `data_utils.py` file found in the `exercises/ex08` directory. As you now know, when you import modules in a running Python program, the module is evaluated only once. Since your Jupyter Notebook _kernel_ is running the entire time you are working on functions in `data_utils.py`, we will use a special extension to automatically reload any changes you make _and save_ in modules you import. The special conventions in the cell below are turning this feature on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoreload of imported modules enabled. Be sure to save your work in other modules!\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "print(\"Autoreload of imported modules enabled. Be sure to save your work in other modules!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data files will be stored in the `data` directory of the workspace. This Notebook is located in `exercises/ex08` directory. If you think of how to _navigate_ from this directory to the `data` directory, you would need to go \"two directories up\" and then \"into the `data` directory\". The constant `DATA_DIRECTORY` defined below uses the convention of two dots to refer to \"one directory up\", so it is a `str` that references the `data` directory _relative_ to this exercise's directory.\n",
    "\n",
    "Then, another constant is established referencing the path to the data file you will use to test your functions in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY=\"../../data\"\n",
    "DATA_FILE_PATH=f\"{DATA_DIRECTORY}/nc_durham_2015_march_21_to_26.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0. Reading Data from a Stored CSV File into Memory\n",
    "\n",
    "In this part of the exercise, you will implement utility functions to read a CSV file from your computer's hard-drive storage into your running program's (Jupyter kernel's) memory. Once in memory, computations over the data set are very fast.\n",
    "\n",
    "By default, your CSV file is read in row-by-row. Storing these rows as a list of \"row\" dictionaries is one way of _representing_ tabular data.\n",
    "\n",
    "### 0.0) Implement the `read_csv_rows` Function\n",
    "\n",
    "Complete the implementation of the `read_csv_rows` function in `data_utils.py` and be sure to save your work when making changes in that file _before_ re-evaluating the cell below to test it.\n",
    "\n",
    "Purpose: Read an entire CSV of data into a `list` of rows, each row represented as `dict[str, str]`.\n",
    "\n",
    "* Function Name: `read_csv_rows`\n",
    "* Parameter: \n",
    "    1. `str` path to CSV file\n",
    "* Return Type: `list[dict[str, str]]` \n",
    "\n",
    "Implementation hint: refer back to the code you wrote in lecture on 10/19 for reading a CSV file. We give you the code for this function.\n",
    "\n",
    "There _should be_ 294 rows and 29 columns read from the `nc_durham_2015_march_21_to_26.csv` stops file. Additionally, the column names should print below those stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jlwilliams90\\Documents\\comp110-22f-workspace\\exercises\\ex08\\data_wrangling.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jlwilliams90/Documents/comp110-22f-workspace/exercises/ex08/data_wrangling.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdata_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m read_csv_rows\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jlwilliams90/Documents/comp110-22f-workspace/exercises/ex08/data_wrangling.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data_rows: \u001b[39mlist\u001b[39m[\u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m read_csv_rows(DATA_FILE_PATH)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jlwilliams90/Documents/comp110-22f-workspace/exercises/ex08/data_wrangling.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data_rows) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'data_utils'"
     ]
    }
   ],
   "source": [
    "from data_utils import read_csv_rows\n",
    "data_rows: list[dict[str, str]] = read_csv_rows(DATA_FILE_PATH)\n",
    "\n",
    "if len(data_rows) == 0:\n",
    "    print(\"Go implement read_csv_rows in data_utils.py\")\n",
    "    print(\"Be sure to save your work before re-evaluating this cell!\")\n",
    "else:\n",
    "    print(f\"Data File Read: {DATA_FILE_PATH}\")\n",
    "    print(f\"{len(data_rows)} rows\")\n",
    "    print(f\"{len(data_rows[0].keys())} columns\")\n",
    "    print(f\"Columns names: {data_rows[0].keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2) `columnar` Function\n",
    "\n",
    "Define and implement this function in `data_utils.py`.\n",
    "\n",
    "Purpose: _Transform_ a table represented as a list of rows (e.g. `list[dict[str, str]]`) into one represented as a dictionary of columns (e.g. `dict[str, list[str]]`).\n",
    "\n",
    "Why is this function useful? Many types of analysis are much easier to perform column-wise.\n",
    "\n",
    "* Function Name: `columnar`\n",
    "* Parameter: `list[dict[str, str]]` - a \"table\" organized as a list of rows\n",
    "* Return Type: `dict[str, list[str]]` - a \"table\" organized as a dictionary of columns\n",
    "\n",
    "Implementation strategy: Establish an empty dictionary to the your column-oriented table you are building up to ultimately return. Loop through each of the column names in the first row of the parameter. Get a list of each column's values via your `column_values` function defined previously. Then, associate the column name with the list of its values in the dictionary you established. After looping through every column name, return the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67c2cea2dfa02739b0de49bc0d5f8f053e7b187cb2e731547eaa2a1aa6ff9c35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
